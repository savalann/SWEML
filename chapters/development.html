
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Model Development and Parameter Tuning &#8212; Use Case Template</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Model Training" href="training.html" />
    <link rel="prev" title="Data Preparation" href="data.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/GeoSMART_logo.svg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Use Case Template</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  About
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://geo-smart.github.io/index.html">
   Geosmart Website
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://foundations.projectpythia.org/landing-page.html">
   Project Pythia Foundations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="about.html">
   About the GeoSMART Snow ML Use Case Library
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter One
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="motivation.html">
   Motivation (Science or Utility)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter Two
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="methods.html">
   Machine Learning Methods and Tools
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter Three
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="data.html">
   Data Preparation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter Four
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Model Development and Parameter Tuning
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter Five
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="training.html">
   Model Training
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter Six
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="evaluation.html">
   Performance Evaluation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter Seven
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="workflow.html">
   Workflow Management / Cloud Computing
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter Eight
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="reproducibility.html">
   Reproducibility
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter Nine
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="conclusion.html">
   Discussion / Conclusion
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter Ten (optional)
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="todo.html">
   Try something on your own
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter Eleven (optional)
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="questions.html">
   Open questions
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter Twelve (optional)
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="troubleshooting.html">
   Trouble Shooting
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Chapter Thirteen
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="example.html">
   Sample Jupyter Notebook
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Reference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../reference/glossary.html">
   Glossaries
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../reference/bibliography.html">
   Bibliography
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/geo-smart/use_case_template/main?urlpath=lab/tree/book/chapters/development.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/geo-smart/use_case_template"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/geo-smart/use_case_template/issues/new?title=Issue%20on%20page%20%2Fchapters/development.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/geo-smart/use_case_template/edit/main/book/chapters/development.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/chapters/development.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-selection-with-gradient-boosted-decision-trees">
   Feature Selection With Gradient Boosted Decision Trees
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#define-region">
   Define Region
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#define-hyperparameter-grid">
   Define Hyperparameter Grid
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#make-dataframe-function">
   Make Dataframe Function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#define-fit-function">
   Define Fit function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-selection-function">
   Feature Selection Function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#prediction-function">
   Prediction Function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#batch-training-function">
   Batch Training Function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regressor-class">
   REGRESSOR Class
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#running-the-lightgbm-for-feature-optimization">
   Running the LightGBM for Feature Optimization
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Model Development and Parameter Tuning</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-selection-with-gradient-boosted-decision-trees">
   Feature Selection With Gradient Boosted Decision Trees
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#define-region">
   Define Region
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#define-hyperparameter-grid">
   Define Hyperparameter Grid
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#make-dataframe-function">
   Make Dataframe Function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#define-fit-function">
   Define Fit function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-selection-function">
   Feature Selection Function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#prediction-function">
   Prediction Function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#batch-training-function">
   Batch Training Function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regressor-class">
   REGRESSOR Class
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#running-the-lightgbm-for-feature-optimization">
   Running the LightGBM for Feature Optimization
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="model-development-and-parameter-tuning">
<h1>Model Development and Parameter Tuning<a class="headerlink" href="#model-development-and-parameter-tuning" title="Permalink to this headline">#</a></h1>
<p>The model pipeline consists of a hybrid-ML technique, utilizing two separate and optimized frameworks outlined in the figure below.Hybrid approaches in ML modeling, thogh more complex, show improved accuracy over traditional single algorithm models. The integration of multiple algorithms allows for more robust models and methods of feature set derivation.
Here, we apply a hybrid approach of first utilizing Gradient Boosted decision Trees to select an optimal model feature space, and follow it with a supervised MLP regression model. Output of the hybrid model is 1-km gridded SWE estimates throughout the study area.</p>
<a class="reference internal image-reference" href="../_images/SWE_model_workflow_V2.png"><img alt="drawing" class="align-center" src="../_images/SWE_model_workflow_V2.png" style="width: 400px;" /></a>
<section id="feature-selection-with-gradient-boosted-decision-trees">
<h2>Feature Selection With Gradient Boosted Decision Trees<a class="headerlink" href="#feature-selection-with-gradient-boosted-decision-trees" title="Permalink to this headline">#</a></h2>
<p>Import the necessary dependencies and path to the parent directory of the model</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">h5py</span>
<span class="kn">import</span> <span class="nn">tables</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="c1">#import contextily as cx</span>
<span class="kn">import</span> <span class="nn">geopandas</span> <span class="k">as</span> <span class="nn">gpd</span>
<span class="kn">from</span> <span class="nn">shapely.geometry</span> <span class="kn">import</span> <span class="n">Point</span>
<span class="kn">import</span> <span class="nn">rasterio</span>
<span class="kn">import</span> <span class="nn">rioxarray</span> <span class="k">as</span> <span class="nn">rxr</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">from</span> <span class="nn">pickle</span> <span class="kn">import</span> <span class="n">dump</span>
<span class="kn">import</span> <span class="nn">sklearn</span>
<span class="kn">import</span> <span class="nn">graphviz</span>
<span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="nn">xgb</span>
<span class="kn">import</span> <span class="nn">lightgbm</span> <span class="k">as</span> <span class="nn">lgbm</span>
<span class="kn">from</span> <span class="nn">platform</span> <span class="kn">import</span> <span class="n">python_version</span>

<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">RFE</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">RFECV</span>
<span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">cv</span>
<span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBRegressor</span>
<span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">plot_importance</span> <span class="k">as</span> <span class="n">plot_importance_XGB</span>
<span class="kn">from</span> <span class="nn">lightgbm</span> <span class="kn">import</span> <span class="n">LGBMRegressor</span>
<span class="kn">from</span> <span class="nn">lightgbm</span> <span class="kn">import</span> <span class="n">plot_importance</span> <span class="k">as</span> <span class="n">plot_importance_LGBM</span>

<span class="nb">print</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="c1"># should be 1.3.0</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="c1"># should be 0.24.1</span>
<span class="nb">print</span><span class="p">(</span><span class="n">python_version</span><span class="p">())</span> 

<span class="c1">#os.chdir(&#39;Your Model Directory Here&#39;)</span>
<span class="c1">#print(os.getcwd())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\rjohnson18\Anaconda3\envs\NSM_env\lib\site-packages\geopandas\_compat.py:111: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.3-CAPI-1.16.1). Conversions between both will be slow.
  warnings.warn(
C:\Users\rjohnson18\Anaconda3\envs\NSM_env\lib\site-packages\xarray\backends\cfgrib_.py:29: UserWarning: Failed to load cfgrib - most likely there is a problem accessing the ecCodes library. Try `import cfgrib` to get the full error message
  warnings.warn(
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.4.3
1.1.1
3.9.12
</pre></div>
</div>
</div>
</div>
</section>
<section id="define-region">
<h2>Define Region<a class="headerlink" href="#define-region" title="Permalink to this headline">#</a></h2>
<p>The first step is to define the Region, here we are using the Northern Colorado Rockies region.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">### load regionalized geospatial data</span>

<span class="c1">### define regions</span>
<span class="n">Region_list</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;N_Co_Rockies&#39;</span><span class="p">]</span>

<span class="c1">### Load H5 train files into dictionary</span>
<span class="n">RegionTrain</span><span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">region</span> <span class="ow">in</span> <span class="n">Region_list</span><span class="p">:</span>
    <span class="n">RegionTrain</span><span class="p">[</span><span class="n">region</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_hdf</span><span class="p">(</span><span class="s1">&#39;./Provided_Data/Final_Training_DF.h5&#39;</span><span class="p">,</span> <span class="n">region</span><span class="p">)</span>
    
</pre></div>
</div>
</div>
</div>
</section>
<section id="define-hyperparameter-grid">
<h2>Define Hyperparameter Grid<a class="headerlink" href="#define-hyperparameter-grid" title="Permalink to this headline">#</a></h2>
<p>Next define a hyperparameter grid dictionary object to be optimized later on during cross-validation splittling.
The ranges here have been tuned to provide good model performance, however you should change the values around and try additional hyperparameters to see how it affects performance and efficieny.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">### hyperparameter grid</span>

<span class="n">LGBM_param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">4</span><span class="p">)),</span>
    <span class="s2">&quot;num_leaves&quot;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">55</span><span class="p">,</span><span class="mi">10</span><span class="p">)),</span>
    <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
    <span class="s2">&quot;subsample&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">],</span>
    <span class="s2">&quot;n_estimators&quot;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span><span class="mi">700</span><span class="p">,</span><span class="mi">100</span><span class="p">))</span>  
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="make-dataframe-function">
<h2>Make Dataframe Function<a class="headerlink" href="#make-dataframe-function" title="Permalink to this headline">#</a></h2>
<p>Now we are ready to define our Gradient Boosting Decision Tree Model.
First, initializing the class parameters and creating the make_dataframe method.
This method formats a dataframe of the data for use in the model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_dataframe</span><span class="p">(</span><span class="n">region</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Dataframe manipulation.&quot;&quot;&quot;</span>

    <span class="n">df</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">region</span><span class="p">)</span>

    <span class="c1">### replace -9999s with nans</span>
    <span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">replace</span><span class="p">([</span><span class="o">-</span><span class="mi">9999</span><span class="p">,</span> <span class="o">-</span><span class="mf">9999.99</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>     

    <span class="c1">### create new index 0 - len(df)</span>
    <span class="n">df</span><span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;index&quot;</span><span class="p">:</span> <span class="s2">&quot;cell_id&quot;</span><span class="p">})</span>
    <span class="k">if</span> <span class="s1">&#39;Date&#39;</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Date&#39;</span><span class="p">])</span> 

    <span class="c1">###create indexed series of cell ids</span>
    <span class="n">id_map</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;cell_id&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
    <span class="n">id_map</span><span class="p">[</span><span class="s1">&#39;Long&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Long&#39;</span><span class="p">]</span>
    <span class="n">id_map</span><span class="p">[</span><span class="s1">&#39;Lat&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Lat&#39;</span><span class="p">]</span>
    <span class="n">id_map</span><span class="p">[</span><span class="s1">&#39;WYWeek&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;WYWeek&#39;</span><span class="p">]</span>
    <span class="n">id_map</span><span class="p">[</span><span class="s1">&#39;elevation_m&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;elevation_m&#39;</span><span class="p">]</span>

    <span class="c1">### shuffle dataframe</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1234</span><span class="p">)</span>

    <span class="c1">### replace special character &#39;:&#39; with &#39;__&#39; </span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="s1">&#39;__&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">df</span><span class="p">,</span> <span class="n">id_map</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="define-fit-function">
<h2>Define Fit function<a class="headerlink" href="#define-fit-function" title="Permalink to this headline">#</a></h2>
<p>Now we define the fit_ method.
This scales the dataframe from the previous step with a Min-Max scaler and splits the data to 25/75% training/testing split.
A cross-vaildation grid search with 5 folds is then performed on the data for the LGBM_param_grid.
We select the best parameters using the .best_params_ parameter and fit the model to those parameters.</p>
<p>The fit model now undergoes the first feature selection with the .Feature_Selection method we define in the next block.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span> <span class="k">def</span> <span class="nf">fit_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">region</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Gridsearch for Parmas, Fit model, and save as instance attribute.&quot;&quot;&quot;</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

        <span class="c1">### Dataframe engineering step</span>
        <span class="n">df</span><span class="p">,</span> <span class="n">id_map</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_dataframe</span><span class="p">(</span><span class="n">region</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

        <span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>


        <span class="c1">###normalize features</span>
        <span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scaled</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
        <span class="c1">#save scaler data here</span>
        <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">scaler</span><span class="p">,</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;/Model/Model_Training/Prev_LGBM/Scalers/&#39;</span><span class="o">+</span><span class="s1">&#39;LGBM_&#39;</span><span class="o">+</span><span class="n">region</span><span class="o">+</span><span class="s1">&#39;_scaler.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">))</span>

        <span class="n">X</span> <span class="o">=</span> <span class="n">df</span>
        <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1234</span><span class="p">)</span>


        <span class="c1">### Fit CV to define optimal hyperparmaeters</span>
        <span class="n">gs</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">estimator</span><span class="p">(),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span><span class="p">,</span>
            <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">refit</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

        <span class="n">gs</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">=</span> <span class="n">gs</span><span class="o">.</span><span class="n">best_score_</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span> <span class="o">=</span> <span class="n">gs</span><span class="o">.</span><span class="n">best_params_</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Best Score:&#39;</span><span class="p">,</span> <span class="n">gs</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Best Params:&#39;</span><span class="p">,</span> <span class="n">gs</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>


        <span class="c1">### Fit the estimator model with the optimal params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span><span class="p">)</span>

        <span class="n">X_train_rfe</span><span class="p">,</span> <span class="n">X_test_rfe</span><span class="p">,</span> <span class="n">y_train_rfe</span><span class="p">,</span> <span class="n">y_test_rfe</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Feature_selection</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

        <span class="n">c_time</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training time&#39;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">c_time</span><span class="p">),</span> <span class="s1">&#39;s&#39;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">X_train_rfe</span><span class="p">,</span> <span class="n">X_test_rfe</span><span class="p">,</span> <span class="n">y_train_rfe</span><span class="p">,</span> <span class="n">y_test_rfe</span><span class="p">,</span> <span class="n">id_map</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="feature-selection-function">
<h2>Feature Selection Function<a class="headerlink" href="#feature-selection-function" title="Permalink to this headline">#</a></h2>
<p>Here we define the <a class="reference external" href="https://www.scikit-yb.org/en/latest/api/model_selection/rfecv.html#:~:text=Recursive%20feature%20elimination%20(RFE)%20is,number%20of%20features%20is%20reached.">Recursive Feature Elimination (RFE)</a>.
Using the sklearn RFECV() function, a minimum of 1 optimal features are chosen for the region based on a 5-fold cross validation.
The less informing features are ten dropped from the train and test dataframes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">Feature_selection</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Identify and and fit model with optimal features &quot;&quot;&quot;</span>
        <span class="c1">### Define RFE with CV model</span>
        <span class="n">min_features_to_select</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># Minimum number of features to consider</span>
        <span class="n">rfecv</span> <span class="o">=</span> <span class="n">RFECV</span><span class="p">(</span>
            <span class="n">estimator</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">min_features_to_select</span><span class="o">=</span><span class="n">min_features_to_select</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">rfecv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

        <span class="c1">### dataframe of optimal features, remove non-optimal features from train/test data </span>
        <span class="n">feat</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Features_raw&#39;</span><span class="p">:</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">}</span>
        <span class="n">RFECV_Feat</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">feat</span><span class="p">)</span>
        <span class="n">RFECV_Feat</span><span class="p">[</span><span class="s1">&#39;Rank&#39;</span><span class="p">]</span><span class="o">=</span> <span class="n">rfecv</span><span class="o">.</span><span class="n">ranking_</span>
        <span class="n">RFECV_Feat</span><span class="p">[</span><span class="s1">&#39;Selected&#39;</span><span class="p">]</span><span class="o">=</span> <span class="n">rfecv</span><span class="o">.</span><span class="n">support_</span>
        <span class="n">RFECV_Feat_opt</span> <span class="o">=</span> <span class="n">RFECV_Feat</span><span class="p">[</span><span class="n">RFECV_Feat</span><span class="p">[</span><span class="s1">&#39;Selected&#39;</span><span class="p">]</span><span class="o">==</span><span class="kc">True</span><span class="p">]</span>
        <span class="n">RFECV_Feat_opt</span> <span class="o">=</span> <span class="n">RFECV_Feat_opt</span><span class="p">[</span><span class="s1">&#39;Features_raw&#39;</span><span class="p">]</span>
        <span class="n">RFECV_Feat_opt</span><span class="o">.</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Features_opt&#39;</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The optimal features are: &#39;</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">RFECV_Feat_opt</span><span class="p">))</span>
        <span class="c1">### use optimal features for final fit data</span>
        <span class="n">X_train</span><span class="o">=</span><span class="n">X_train</span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">RFECV_Feat_opt</span><span class="p">)]</span>
        <span class="n">X_test</span><span class="o">=</span><span class="n">X_test</span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">RFECV_Feat_opt</span><span class="p">)]</span>

        <span class="c1">### fit model with optimal parmas &amp; optimal # of featuress</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>


        <span class="c1">### Plot number of features vs. cross-validation scores</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Number of features selected&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Cross validation score (accuracy)&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">min_features_to_select</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">rfecv</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s2">&quot;mean_test_score&quot;</span><span class="p">])</span> <span class="o">+</span> <span class="n">min_features_to_select</span><span class="p">),</span>
            <span class="n">rfecv</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s2">&quot;mean_test_score&quot;</span><span class="p">])</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Optimal number of features : </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">rfecv</span><span class="o">.</span><span class="n">n_features_</span><span class="p">)</span>

        <span class="c1">### Revert special character &#39;__&#39; with &#39;:&#39;</span>
        <span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;(_)\1+&quot;</span><span class="p">,</span> <span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
        <span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;(_)\1+&quot;</span><span class="p">,</span> <span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="prediction-function">
<h2>Prediction Function<a class="headerlink" href="#prediction-function" title="Permalink to this headline">#</a></h2>
<p>Next we may define a .predict_ method on the Decision tree model to predict SWE against the test locations.
We will ultimately not use this prediction as the Nueral Net proves more robust, however it can be insightful for comparing the diffent algorithm performance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">predict_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_test</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generate model predictions.&quot;&quot;&quot;</span>

        <span class="n">preds</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>

        <span class="c1">### correct negative predictions</span>
        <span class="n">preds</span><span class="p">[</span><span class="n">preds</span> <span class="o">&lt;</span><span class="mi">0</span><span class="p">]</span><span class="o">=</span><span class="mi">0</span>

        <span class="k">return</span> <span class="n">preds</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="batch-training-function">
<h2>Batch Training Function<a class="headerlink" href="#batch-training-function" title="Permalink to this headline">#</a></h2>
<p>Rather than indivdually call each method, we can create a new method, called .Batch_Train that will run through the steps we just defined.
This will take in our paramater objects and return a pickle file of the optimal features (“opt_features_final.pkl) for the region that will be used to train the Neural Net in the following steps.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">Batch_Train</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">algorithm</span><span class="p">,</span> <span class="n">parameter_grid</span><span class="p">,</span> <span class="n">Region_list</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Batch train regression model and produce testing prediction.</span>
<span class="sd">    Args:</span>
<span class="sd">        algorithm (model object): Regressor to be fit (XGBRegressor, LGBMRgressor)</span>
<span class="sd">        param_grid (dict): Hyperparameter grid</span>
<span class="sd">        Region_list (list): List of regions to be evaluated</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">split_dict</span><span class="o">=</span><span class="p">{}</span>
    <span class="n">prediction_dict</span><span class="o">=</span><span class="p">{}</span>
    <span class="n">features_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="c1">### define prefix for path based on algorithm desired</span>
    <span class="k">if</span> <span class="n">algorithm</span> <span class="o">==</span> <span class="n">XGBRegressor</span><span class="p">:</span>
        <span class="n">path_name</span> <span class="o">=</span> <span class="s1">&#39;XGB&#39;</span>
        <span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">plot_importance</span>
    <span class="k">elif</span> <span class="n">algorithm</span> <span class="o">==</span> <span class="n">LGBMRegressor</span><span class="p">:</span>
        <span class="n">path_name</span> <span class="o">=</span> <span class="s1">&#39;LGBM&#39;</span>
        <span class="kn">from</span> <span class="nn">lightgbm</span> <span class="kn">import</span> <span class="n">plot_importance</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Algorithm not recognized. Must be XGBRegressor or LGBMRegressor.&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">region</span> <span class="ow">in</span> <span class="n">Region_list</span><span class="p">:</span>
        <span class="c1">###Instantiate Model</span>
        <span class="n">region_model</span> <span class="o">=</span> <span class="n">REGRESSOR</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">estimator</span><span class="o">=</span><span class="n">algorithm</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">parameter_grid</span><span class="p">)</span>

        <span class="c1">###Fit region model and add dictionary entry for region test-train data, save fit model to file.</span>
        <span class="c1">###Dictformat is, split_dict{&#39;region&#39;: [X_train, X_test, y_train, y_test, cell_id]}</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">region</span><span class="p">,</span><span class="s1">&#39;:&#39;</span><span class="p">)</span>
        <span class="n">split_dict</span><span class="p">[</span><span class="n">region</span><span class="p">]</span> <span class="o">=</span> <span class="n">region_model</span><span class="o">.</span><span class="n">fit_</span><span class="p">(</span><span class="n">region</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Saving Model&#39;</span><span class="p">)</span>
        <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">region_model</span><span class="p">,</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;./Model/Model_Training/LGBM/LGBM_&quot;</span><span class="o">+</span><span class="n">region</span><span class="o">+</span><span class="s2">&quot;.pkl&quot;</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">))</span>

        <span class="c1">###Generate predictions and add to prediction dictionary,</span>
        <span class="c1">###Dict format is, prediction_dict{&#39;region&#39;: [preds]}</span>
        <span class="n">prediction_dict</span><span class="p">[</span><span class="n">region</span><span class="p">]</span> <span class="o">=</span> <span class="n">region_model</span><span class="o">.</span><span class="n">predict_</span><span class="p">(</span><span class="n">split_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">region</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span>

        <span class="c1">### plot predictions if desired</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
        <span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s2">&quot;whitegrid&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">split_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">region</span><span class="p">)[</span><span class="mi">3</span><span class="p">],</span> <span class="n">prediction_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">region</span><span class="p">),</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;b&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,(</span><span class="n">prediction_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">region</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">+</span><span class="mi">10</span><span class="p">)],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,(</span><span class="n">prediction_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">region</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">+</span><span class="mi">10</span><span class="p">)],</span> <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;.1&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="n">split_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">region</span><span class="p">)[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">+</span><span class="mi">5</span><span class="p">)])</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([(</span><span class="n">prediction_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">region</span><span class="p">)</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">-</span><span class="mi">1</span><span class="p">),(</span><span class="n">prediction_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">region</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">+</span><span class="mi">5</span><span class="p">)])</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">region</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Truth&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Prediction&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
        <span class="n">rmse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">split_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">region</span><span class="p">)[</span><span class="mi">3</span><span class="p">],</span> <span class="n">prediction_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">region</span><span class="p">),</span> <span class="n">squared</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">region</span><span class="p">,</span> <span class="s2">&quot;RMSE:&quot;</span><span class="p">,</span> <span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">rmse</span><span class="p">,</span><span class="mi">3</span><span class="p">)))</span>

        <span class="c1">###Optimal Features dictionary </span>
        <span class="n">features_dict</span><span class="p">[</span><span class="n">region</span><span class="p">]</span> <span class="o">=</span> <span class="n">split_dict</span><span class="p">[</span><span class="n">region</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">columns</span>


    <span class="c1">###Save output dictionaries to file</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">split_dict</span><span class="p">,</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;./Model/Model_Training/LGBM/Output/&quot;</span><span class="o">+</span><span class="n">path_name</span><span class="o">+</span><span class="s2">&quot;_split_dict_final.pkl&quot;</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">))</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">prediction_dict</span><span class="p">,</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;./Model/Model_Training/LGBM/Output/&quot;</span><span class="o">+</span><span class="n">path_name</span><span class="o">+</span><span class="s2">&quot;_prediction_dict_final.pkl&quot;</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">))</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">features_dict</span><span class="p">,</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;./Model/Model_Training/LGBM/Output/opt_features_final.pkl&quot;</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">split_dict</span><span class="p">,</span> <span class="n">prediction_dict</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="regressor-class">
<h2>REGRESSOR Class<a class="headerlink" href="#regressor-class" title="Permalink to this headline">#</a></h2>
<p>We defined all of the key functions of the LightGBM framework but need a method for each function to “talk” to another.
Addressing this, we develop a <a class="reference external" href="https://realpython.com/python3-object-oriented-programming/">Object Oriented Programming (OOB)</a> function that we label the REGRESSOR Class
In the REGRESSOR class, we place all of the functions within and use the self. command to support variable “pointing”.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">REGRESSOR</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Regression optimization model class.</span>
<span class="sd">    Args:</span>
<span class="sd">        target (str): target to be modeled.</span>
<span class="sd">        data (dict): Dictionary of dataframes containing training/testing data</span>
<span class="sd">        estimator (model object): type of model to be fit.</span>
<span class="sd">        param_grid (dict): hyperparameter grid</span>
<span class="sd">        model (fit XGBRegressor, LGBMRegessor, etc..): the fit model object</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">estimator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">target</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">estimator</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_grid</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
    
        <span class="c1">#@staticmethod</span>
    <span class="k">def</span> <span class="nf">make_dataframe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">region</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Dataframe manipulation.&quot;&quot;&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Making training dataframe.&#39;</span><span class="p">)</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">region</span><span class="p">)</span>
        
        <span class="c1">### replace -9999s with nans</span>
        <span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">replace</span><span class="p">([</span><span class="o">-</span><span class="mi">9999</span><span class="p">,</span> <span class="o">-</span><span class="mf">9999.99</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>     
        
        <span class="c1">### create new index 0 - len(df)</span>
        <span class="n">df</span><span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">df</span> <span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;index&quot;</span><span class="p">:</span> <span class="s2">&quot;cell_id&quot;</span><span class="p">})</span>
        <span class="k">if</span> <span class="s1">&#39;Date&#39;</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Date&#39;</span><span class="p">])</span> 
        
        <span class="c1">###create indexed series of cell ids</span>
        <span class="n">id_map</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;cell_id&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
        <span class="n">id_map</span><span class="p">[</span><span class="s1">&#39;Long&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Long&#39;</span><span class="p">]</span>
        <span class="n">id_map</span><span class="p">[</span><span class="s1">&#39;Lat&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Lat&#39;</span><span class="p">]</span>
        <span class="n">id_map</span><span class="p">[</span><span class="s1">&#39;WYWeek&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;WYWeek&#39;</span><span class="p">]</span>
        <span class="n">id_map</span><span class="p">[</span><span class="s1">&#39;elevation_m&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;elevation_m&#39;</span><span class="p">]</span>

        <span class="c1">### shuffle dataframe</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1234</span><span class="p">)</span>
        
        <span class="c1">### replace special character &#39;:&#39; with &#39;__&#39; </span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="s1">&#39;__&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
        
        <span class="k">return</span> <span class="n">df</span><span class="p">,</span> <span class="n">id_map</span>
    
    <span class="k">def</span> <span class="nf">fit_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">region</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Fitting the model.&#39;</span><span class="p">)</span>
        <span class="sd">&quot;&quot;&quot;Gridsearch for Parmas, Fit model, and save as instance attribute.&quot;&quot;&quot;</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

        <span class="c1">### Dataframe engineering step</span>
        <span class="n">df</span><span class="p">,</span> <span class="n">id_map</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_dataframe</span><span class="p">(</span><span class="n">region</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

        <span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>


        <span class="c1">###normalize features</span>
        <span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scaled</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
        <span class="c1">#save scaler data here</span>
        <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">scaler</span><span class="p">,</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;./Model/Model_Training/LGBM/Scalers/&#39;</span><span class="o">+</span><span class="s1">&#39;LGBM_&#39;</span><span class="o">+</span><span class="n">region</span><span class="o">+</span><span class="s1">&#39;_scaler.pkl&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">))</span>

        <span class="n">X</span> <span class="o">=</span> <span class="n">df</span>
        <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1234</span><span class="p">)</span>


        <span class="c1">### Fit CV to define optimal hyperparmaeters</span>
        <span class="n">gs</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">estimator</span><span class="p">(),</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span><span class="p">,</span>
            <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">refit</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Performing the LGBM GridSearch to identify optimal hyperparameters.&#39;</span><span class="p">)</span>
        <span class="n">gs</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">best_score</span> <span class="o">=</span> <span class="n">gs</span><span class="o">.</span><span class="n">best_score_</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span> <span class="o">=</span> <span class="n">gs</span><span class="o">.</span><span class="n">best_params_</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Best Score:&#39;</span><span class="p">,</span> <span class="n">gs</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Best Params:&#39;</span><span class="p">,</span> <span class="n">gs</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>


        <span class="c1">### Fit the estimator model with the optimal params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Optimizig Features&#39;</span><span class="p">)</span>
        <span class="n">X_train_rfe</span><span class="p">,</span> <span class="n">X_test_rfe</span><span class="p">,</span> <span class="n">y_train_rfe</span><span class="p">,</span> <span class="n">y_test_rfe</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Feature_selection</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

        <span class="n">c_time</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training time&#39;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">c_time</span><span class="p">),</span> <span class="s1">&#39;s&#39;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">X_train_rfe</span><span class="p">,</span> <span class="n">X_test_rfe</span><span class="p">,</span> <span class="n">y_train_rfe</span><span class="p">,</span> <span class="n">y_test_rfe</span><span class="p">,</span> <span class="n">id_map</span>


    <span class="k">def</span> <span class="nf">Feature_selection</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Identify and and fit model with optimal features &quot;&quot;&quot;</span>
        <span class="c1">### Define RFE with CV model</span>
        <span class="n">min_features_to_select</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># Minimum number of features to consider</span>
        <span class="n">rfecv</span> <span class="o">=</span> <span class="n">RFECV</span><span class="p">(</span>
            <span class="n">estimator</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">min_features_to_select</span><span class="o">=</span><span class="n">min_features_to_select</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">rfecv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

        <span class="c1">### dataframe of optimal features, remove non-optimal features from train/test data </span>
        <span class="n">feat</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Features_raw&#39;</span><span class="p">:</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">}</span>
        <span class="n">RFECV_Feat</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">feat</span><span class="p">)</span>
        <span class="n">RFECV_Feat</span><span class="p">[</span><span class="s1">&#39;Rank&#39;</span><span class="p">]</span><span class="o">=</span> <span class="n">rfecv</span><span class="o">.</span><span class="n">ranking_</span>
        <span class="n">RFECV_Feat</span><span class="p">[</span><span class="s1">&#39;Selected&#39;</span><span class="p">]</span><span class="o">=</span> <span class="n">rfecv</span><span class="o">.</span><span class="n">support_</span>
        <span class="n">RFECV_Feat_opt</span> <span class="o">=</span> <span class="n">RFECV_Feat</span><span class="p">[</span><span class="n">RFECV_Feat</span><span class="p">[</span><span class="s1">&#39;Selected&#39;</span><span class="p">]</span><span class="o">==</span><span class="kc">True</span><span class="p">]</span>
        <span class="n">RFECV_Feat_opt</span> <span class="o">=</span> <span class="n">RFECV_Feat_opt</span><span class="p">[</span><span class="s1">&#39;Features_raw&#39;</span><span class="p">]</span>
        <span class="n">RFECV_Feat_opt</span><span class="o">.</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Features_opt&#39;</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The optimal features are: &#39;</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">RFECV_Feat_opt</span><span class="p">))</span>
        <span class="c1">### use optimal features for final fit data</span>
        <span class="n">X_train</span><span class="o">=</span><span class="n">X_train</span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">RFECV_Feat_opt</span><span class="p">)]</span>
        <span class="n">X_test</span><span class="o">=</span><span class="n">X_test</span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">RFECV_Feat_opt</span><span class="p">)]</span>

        <span class="c1">### fit model with optimal parmas &amp; optimal # of featuress</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">param_grid</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>


        <span class="c1">### Plot number of features vs. cross-validation scores</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Number of features selected&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Cross validation score (accuracy)&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">min_features_to_select</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">rfecv</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s2">&quot;mean_test_score&quot;</span><span class="p">])</span> <span class="o">+</span> <span class="n">min_features_to_select</span><span class="p">),</span>
            <span class="n">rfecv</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s2">&quot;mean_test_score&quot;</span><span class="p">])</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Optimal number of features : </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">rfecv</span><span class="o">.</span><span class="n">n_features_</span><span class="p">)</span>

        <span class="c1">### Revert special character &#39;__&#39; with &#39;:&#39;</span>
        <span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;(_)\1+&quot;</span><span class="p">,</span> <span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
        <span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;(_)\1+&quot;</span><span class="p">,</span> <span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span>
        

    <span class="k">def</span> <span class="nf">predict_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_test</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generate model predictions.&quot;&quot;&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Making a prediction on testing data.&#39;</span><span class="p">)</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>

        <span class="c1">### correct negative predictions</span>
        <span class="n">preds</span><span class="p">[</span><span class="n">preds</span> <span class="o">&lt;</span><span class="mi">0</span><span class="p">]</span><span class="o">=</span><span class="mi">0</span>

        <span class="k">return</span> <span class="n">preds</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="running-the-lightgbm-for-feature-optimization">
<h2>Running the LightGBM for Feature Optimization<a class="headerlink" href="#running-the-lightgbm-for-feature-optimization" title="Permalink to this headline">#</a></h2>
<p>Finally, we can enter our parameter values into the Batch_Train method and have the model define our optimal features. These feature are crucial for training the Neural Network.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="n">splits_LGBM</span> <span class="p">,</span> <span class="n">preds_LGBM</span> <span class="o">=</span> <span class="n">Batch_Train</span><span class="p">(</span><span class="s1">&#39;SWE&#39;</span><span class="p">,</span> <span class="n">RegionTrain</span><span class="p">,</span> <span class="n">LGBMRegressor</span><span class="p">,</span> <span class="n">LGBM_param_grid</span><span class="p">,</span> <span class="n">Region_list</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>N_Co_Rockies :
Fitting the model.
Making training dataframe.
Performing the LGBM GridSearch to identify optimal hyperparameters.
Best Score: 0.8568292366930509
Best Params: {&#39;learning_rate&#39;: 0.1, &#39;max_depth&#39;: 11, &#39;n_estimators&#39;: 400, &#39;num_leaves&#39;: 25, &#39;subsample&#39;: 0.7}
Optimizig Features
The optimal features are:  [&#39;Long&#39;, &#39;Lat&#39;, &#39;elevation_m&#39;, &#39;prev_SWE&#39;, &#39;WYWeek&#39;, &#39;northness&#39;, &#39;SWE_SNOTEL__1014_CO_SNTL&#39;, &#39;SWE_SNOTEL__1030_CO_SNTL&#39;, &#39;SWE_SNOTEL__1031_CO_SNTL&#39;, &#39;SWE_SNOTEL__1032_CO_SNTL&#39;, &#39;SWE_SNOTEL__1033_CO_SNTL&#39;, &#39;SWE_SNOTEL__1040_CO_SNTL&#39;, &#39;SWE_SNOTEL__1061_CO_SNTL&#39;, &#39;SWE_SNOTEL__1100_CO_SNTL&#39;, &#39;SWE_SNOTEL__1101_CO_SNTL&#39;, &#39;SWE_SNOTEL__1120_CO_SNTL&#39;, &#39;SWE_SNOTEL__1122_CO_SNTL&#39;, &#39;SWE_SNOTEL__1123_CO_SNTL&#39;, &#39;SWE_SNOTEL__1141_CO_SNTL&#39;, &#39;SWE_SNOTEL__1161_CO_SNTL&#39;, &#39;SWE_SNOTEL__1186_CO_SNTL&#39;, &#39;SWE_SNOTEL__1187_CO_SNTL&#39;, &#39;SWE_SNOTEL__1251_CO_SNTL&#39;, &#39;SWE_SNOTEL__1252_CO_SNTL&#39;, &#39;SWE_SNOTEL__322_CO_SNTL&#39;, &#39;SWE_SNOTEL__335_CO_SNTL&#39;, &#39;SWE_SNOTEL__345_CO_SNTL&#39;, &#39;SWE_SNOTEL__380_CO_SNTL&#39;, &#39;SWE_SNOTEL__409_CO_SNTL&#39;, &#39;SWE_SNOTEL__412_CO_SNTL&#39;, &#39;SWE_SNOTEL__415_CO_SNTL&#39;, &#39;SWE_SNOTEL__426_CO_SNTL&#39;, &#39;SWE_SNOTEL__438_CO_SNTL&#39;, &#39;SWE_SNOTEL__467_CO_SNTL&#39;, &#39;SWE_SNOTEL__485_CO_SNTL&#39;, &#39;SWE_SNOTEL__505_CO_SNTL&#39;, &#39;SWE_SNOTEL__531_CO_SNTL&#39;, &#39;SWE_SNOTEL__542_CO_SNTL&#39;, &#39;SWE_SNOTEL__556_CO_SNTL&#39;, &#39;SWE_SNOTEL__564_CO_SNTL&#39;, &#39;SWE_SNOTEL__565_CO_SNTL&#39;, &#39;SWE_SNOTEL__607_CO_SNTL&#39;, &#39;SWE_SNOTEL__622_CO_SNTL&#39;, &#39;SWE_SNOTEL__658_CO_SNTL&#39;, &#39;SWE_SNOTEL__663_CO_SNTL&#39;, &#39;SWE_SNOTEL__669_CO_SNTL&#39;, &#39;SWE_SNOTEL__680_CO_SNTL&#39;, &#39;SWE_SNOTEL__682_CO_SNTL&#39;, &#39;SWE_SNOTEL__709_CO_SNTL&#39;, &#39;SWE_SNOTEL__717_CO_SNTL&#39;, &#39;SWE_SNOTEL__718_CO_SNTL&#39;, &#39;SWE_SNOTEL__793_CO_SNTL&#39;, &#39;SWE_SNOTEL__825_CO_SNTL&#39;, &#39;SWE_SNOTEL__827_CO_SNTL&#39;, &#39;SWE_SNOTEL__838_CO_SNTL&#39;, &#39;SWE_SNOTEL__842_CO_SNTL&#39;, &#39;SWE_SNOTEL__869_CO_SNTL&#39;, &#39;SWE_SNOTEL__913_CO_SNTL&#39;, &#39;SWE_SNOTEL__936_CO_SNTL&#39;, &#39;SWE_SNOTEL__937_CO_SNTL&#39;, &#39;SWE_SNOTEL__939_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__1014_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__1014_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__1030_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__1030_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__1031_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__1031_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__1032_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__1032_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__1033_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__1033_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__1040_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__1040_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__1061_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__1061_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__1100_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__1100_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__1101_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__1101_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__1120_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__1120_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__1122_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__1123_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__1123_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__1141_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__1161_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__1161_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__1186_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__1186_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__1187_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__1187_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__1251_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__1251_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__1252_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__322_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__322_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__335_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__335_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__345_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__380_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__380_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__409_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__409_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__412_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__415_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__415_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__426_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__438_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__438_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__457_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__467_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__485_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__485_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__505_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__505_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__531_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__531_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__542_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__556_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__556_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__564_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__564_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__565_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__607_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__607_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__622_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__622_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__658_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__658_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__663_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__669_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__669_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__680_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__680_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__682_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__682_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__709_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__709_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__717_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__717_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__718_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__793_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__793_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__825_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__825_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__827_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__827_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__838_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__838_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__842_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__842_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__869_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__869_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__913_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__935_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__935_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__936_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__936_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__937_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__937_CO_SNTL&#39;, &#39;Prev_SWE_SNOTEL__939_CO_SNTL&#39;, &#39;Delta_SWE_SNOTEL__939_CO_SNTL&#39;]
</pre></div>
</div>
<img alt="../_images/development_20_1.png" src="../_images/development_20_1.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimal number of features : 162
Training time 4389 s
Saving Model
Making a prediction on testing data.
</pre></div>
</div>
<img alt="../_images/development_20_3.png" src="../_images/development_20_3.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>N_Co_Rockies RMSE: 4.268
CPU times: total: 4min 10s
Wall time: 1h 13min 9s
</pre></div>
</div>
</div>
</div>
<p>Next <a class="reference internal" href="training.html"><span class="doc std std-doc">Chapter</span></a>..</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "nsm_env"
        },
        kernelOptions: {
            kernelName: "nsm_env",
            path: "./chapters"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'nsm_env'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="data.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Data Preparation</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="training.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Model Training</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By eScience Institute, University of Washington<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>